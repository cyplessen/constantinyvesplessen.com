[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "News",
    "section": "",
    "text": "Upcoming talk at EACLIPT 2022\n\n\nUsing multiverse meta-analyses to investigate the robustness of mental health research on psychological treatments for depression and digital interventions for anxiety\n\n\n\nconference\n\n\nmultiverse\n\n\n\n\n\n\nNov 12, 2022\n\n\n\n\n\n\n\nUpcoming talk at DGPPN 2022\n\n\nThe robustness of the efficacy of digital interventions for anxiety: an umbrella review and multiverse meta-analysis \n\n\n\nconference\n\n\nmultiverse\n\n\n\n\n\n\nNov 23, 2022\n\n\n\n\n\n\n\nExploring the efficacy of psychological treatments for depression: a multiverse meta-analysis protocol\n\n\n\n\n\n\npublication\n\n\nmultiverse\n\n\n\n\n\n\n\n\n\n\n\nSIPS 2022\n\n\nWorkshop: Multiverse Analyses - Introduction and Applications\n\n\n\nconference\n\n\nmultiverse\n\n\n\n\n\n\n\n\n\n\n\nISOQOL 2022\n\n\nModeling general populations’ reference data for PROMIS item banks (Physical Functioning, Upper Extremities, and Pain interference) in multiple countries using quantile regression.\n\n\n\nconference\n\n\nreference data\n\n\npsychometrics\n\n\n\n\n\n\n\n\n\n\n\nPHO 2021\n\n\nDifferential item functioning of PROMIS physical functioning ceiling items across Argentina, Germany and the US.\n\n\n\nconference\n\n\ndifferential item functioning\n\n\npsychometrics\n\n\n\n\n\n\n\n\n\n\n\nESMR 2022\n\n\nWhat if…? A very short primer on conducting multiverse meta-analyses in R\n\n\n\nconference\n\n\nmultiverse\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "2024\n\n\nCuijpers, P., Harrer, M., Miguel, C., Ciharova, M., Basic, D., Cristea, I. A., de Ponti, N., Driessen, E., Hamblen, J., Larsen, S. E., Matbouriahi, M., Papola, D., Pauley, D., Plessen, C. Y., Pfund, R. A., Setkowski, K., Schnurr, P. P., van Ballegooijen, W., Wang, Y., Riper, H., van Straten, A., Sijbrandij, M., Furukawa, T. A., & Karyotaki, E. (2024). Cognitive behavior therapy for mental disorders in adults: A unified series of meta-analyses across 375 randomized trials. Under Review: JAMA Psychiatry.\nHarrer, M., Miguel, C., van Ballegooijen, W., Ciharova, M., Plessen, C. Y., Kuper, P., Sprenger, A. A., Buntrock, C., Papola, D., Cristea, I. A., de Ponti, N., Basic, D., Pauley, D., Driessen, E., Quero, S., Grimaldos, J., Fernández Buendía, S., Botella, C., Hamblen, J. L., Schnurr, P. P., Larsen, S. E., Pfund, R. A., Motrico, E., Goméz-Goméz, I., Setkowski, K., Matbouriahi, M., Wang, Y., Rawee, J., Riper, H., van Straten, A., Sijbrandij, M., Leucht, S., Furukawa, T. A., Karyotaki, E., & Cuijpers, P. (2024). Supersizing meta-analysis of psychological interventions: Features and findings of the “Metapsy” meta-analytic research domain. Under Review.\nPlessen, C. Y. (2024). Research synthesis of psychological interventions for mental health. Doctoral dissertation, Vrije Universiteit Amsterdam. https://research.vu.nl/en/publications/research-synthesis-of-psychological-interventions-for-mental-heal.\nMiguel, C., Harrer, M., Karyotaki, E., Plessen, C. Y., Ciharova, M., Furukawa, T. A., Cristea, I. A., & Cuijpers, P. (2024). Self-reports vs clinician ratings of efficacies of psychotherapies for depression: A meta-analysis of randomized trials. Under Review.\nScholz, C., Schmigalle, P., Plessen, C. Y., Liegl, G., Vajkoczy, P., Prasser, F., Rose, M., & Obbarius, A. (2024). The effect of self-management techniques on relevant outcomes in chronic low back pain: A systematic review and meta-analysis. European Journal of Pain, 28(4), 532–550. https://doi.org/10.1002/ejp.2221.\nCuijpers, P., Miguel, C., Ciharova, M., Harrer, M., Basic, D., Cristea, I. A., de Ponti, N., Driessen, E., Hamblen, J., Larsen, S. E., Matbouriahi, M., Papola, D., Pauley, D., Plessen, C. Y., Pfund, R. A., Setkowski, K., Schnurr, P. P., van Ballegooijen, W., Wang, Y., Riper, H., & Karyotaki, E. (2024). Absolute and relative outcomes of psychotherapies for eight mental disorders: A systematic review and meta-analysis. World Psychiatry, 23(2), 267–275. https://doi.org/10.1002/wps.21203.\nPlessen, C. Y., Panagiotopoulou, O. M., Tong, L., Cuijpers, P., & Karyotaki, E. (2024). Digital mental health interventions for the treatment of depression: A multiverse meta-analysis. Journal of Affective Disorders, 369, 1031–1044. https://doi.org/10.1016/j.jad.2024.10.018.\nCuijpers, P., Miguel, C., Harrer, M., Plessen, C. Y., Ciharova, M., Papola, D., Ebert, D., & Karyotaki, E. (2024). Randomised trials on psychotherapy for depression: Methods of a ‘meta-analytic research domain.’ Under Review: Systematic Reviews.\nPlessen, C. Y., Hartmann, C., Heng, M., Pesantez, R., Fischer, F., & Rose, M. (2024). Differential item functioning between English, German, and Spanish PROMIS® physical function ceiling items. In Press: Quality of Life Review.\nPlessen, C. Y., Liegl, G., Hartmann, C., Heng, M., Joeris, A., Kaat, A. J., Schalet, B. D., Fischer, F., Rose, M., & AOBERT Consortium (2024). How are age, gender, and country differences associated with PROMIS physical function, upper extremity, and pain interference scores? Clinical Orthopaedics and Related Research, 482(2), 244–256. https://doi.org/10.1097/CORR.0000000000002798.\n\n\n\n\n2023\n\n\nCuijpers, P., Miguel, C., Harrer, M., Plessen, C. Y., et al. (2023). Psychological treatment of depression: A systematic overview of a ‘meta-analytic research domain.’ Journal of Affective Disorders, 335, 141–151. https://doi.org/10.1016/j.jad.2023.05.011.\nHarrison, C. J., Plessen, C. Y., Liegl, G., Rodrigues, J. N., Sabah, S. A., Beard, D. J., & Fischer, F. (2023). Overcoming floor and ceiling effects in knee arthroplasty outcome measurement. Bone & Joint Research, 12(10), 624–635. https://doi.org/10.1302/2046-3758.1210.BJR-2022-0457.R1.\nConrad, J. H., Plessen, C. Y., Liegl, G., Rodrigues, J. N., Sabah, S. A., Beard, D. J., & Fischer, F. (2023). Item response theory may account for unequal item weighting and individual-level measurement error in trials that use PROMs: A psychometric sensitivity analysis of the TOPKAT trial. Journal of Clinical Epidemiology, 158, 62–69. https://doi.org/10.1016/j.jclinepi.2023.03.013.\nPlessen, C. Y., Karyotaki, E., Miguel, C., Ciharova, M., & Cuijpers, P. (2023). Exploring the efficacy of psychotherapies for depression: A multiverse meta-analysis. BMJ Mental Health, 26(1), e300626. https://doi.org/10.1136/bmjment-2022-300626.\nCuijpers, P., Miguel, C., Harrer, M., Plessen, C. Y., et al. (2023). Cognitive behavior therapy vs. control conditions, other psychotherapies, pharmacotherapies, and combined treatment for depression: A comprehensive meta-analysis including 409 trials with 52,702 patients. World Psychiatry, 22(1), 105–115. https://doi.org/10.1002/wps.21069.\nCuijpers, P., Miguel, C., Harrer, M., Plessen, C. Y., Ciharova, M., Papola, D., Ebert, D., & Karyotaki, E. (2023). Psychological treatment of depression with other comorbid mental disorders: Systematic review and meta-analysis. Cognitive Behaviour Therapy. https://doi.org/10.1080/16506073.2023.2166578.\n\n\n\n\n2022 and Before\n\n\nPlessen, C. Y., Karyotaki, E., & Cuijpers, P. (2022). Exploring the efficacy of psychological treatments for depression: A multiverse meta-analysis protocol. BMJ Open, 12(1), e050197. https://doi.org/10.1136/bmjopen-2021-050197.\nPlessen, C. Y., Gyimesi, M. L., Kern, B. M. J., Fritz, T., Catalán Lorca, M. V., Voracek, M., & Tran, U. S. (2020). Associations between academic dishonesty and personality: A pre-registered multilevel meta-analysis. PsyArXiv. https://psyarxiv.com/pav2f/.\nPlessen, C. Y., Lammer, A., Tran, U. S., & Voracek, M. (2020). Twin-singleton differences in intelligence: An updated and pre-registered meta-analysis. Manuscript in preparation.\nPlessen, C. Y., Franken, F., Kathofer, M., Kotlyar, E., Maierwieser, R. J., Mayer, A., Rattner, K., Schmid, R. R., Sobisch, M., Ster, C., Wolfmayer, C., & Tran, U. S. (2020). Humor-styles and personality traits: An updated meta-analysis. Personality and Individual Differences, 154, 109676. https://doi.org/10.1016/j.paid.2019.109676.\nKossmeier, K., Vilsmeier, J., Dittrich, R., Fritz, T., Kolmanz, C., Plessen, C. Y., Slowik, A., Tran, U. S., & Voracek, M. (2019). Long-term trends (1980–2017) in the N-pact factor: Comparative meta-research of journals in personality psychology and individual differences research. Zeitschrift für Psychologie, 227, 293–302. https://doi.org/10.1027/2151-2604/a000384.\nPlessen, C. Y. (2017). Who smokes and drinks? Formal education and time perspective as predictors of differences in alcohol and tobacco intake. Unpublished bachelor’s thesis. University of Vienna.\nPlessen, C. Y., Boeckle, M., Liegl, G., Leitner, A., Schneider, A., Preining, B., & Pieh, C. (2016). [Supply and demand analysis for psychotherapy in Austria] Bedarfsanalyse für ambulante Psychotherapie in Österreich. Psychologische Medizin, 3, 4–9.\nLiegl, G., Plessen, C. Y., Leitner, A., Boeckle, M., & Pieh, C. (2015). Guided self-help interventions for irritable bowel syndrome: A systematic review and meta-analysis. European Journal of Gastroenterology & Hepatology, 27, 1209–1221. https://doi.org/10.1097/MEG.0000000000000428."
  },
  {
    "objectID": "posts/talk-3.html",
    "href": "posts/talk-3.html",
    "title": "ESMR 2022",
    "section": "",
    "text": "Abstract\nEven though conventional meta-analyses provide an overview of the published literature on a given research question, they do not consider different paths that could have been taken in selecting or analyzing the data. Most importantly, multiple meta-analyses with overlapping research questions can reach different conclusions due to differences in inclusion and exclusion criteria, or data analytical decisions. It is therefore crucial to evaluate the influence such choices might have on the result of each meta-analysis. Was the meta-analytical method and exclusion criteria decisive, or is the same result reached via multiple analytical strategies? What if a meta-analysts would have decided to go a different path—would the same outcome occur? Ensuring that the conclusions of a meta-analysis are not disproportionately influenced by data analytical decisions, a multiverse meta-analysis can provide the entire picture and underpin the robustness of the findings—or lack thereof—by conducting multiple, namely all possible and reasonable meta-analyses at once. Hereby, multiverse meta-analyses provide a research integration like umbrella reviews yet additionally investigate the influence flexibility in data analysis could have on the resulting summary effect size. Importantly, in contrast to umbrella reviews, a multiverse analysis also quantitatively summarizes the results and includes not yet conducted meta-analyses. During the talk I will give a more detailed insight into this potent method, and run through the multiverse of meta-analyses on the efficacy of psychological treatments for depression as an empirical example.\n\n\nLink to Video of Presentation"
  },
  {
    "objectID": "posts/talk-1.html",
    "href": "posts/talk-1.html",
    "title": "ISOQOL 2022",
    "section": "",
    "text": "Conference Abstract\nAims: The use of PROs in research and clinical practice requires availability of appropriate and relevant comparison data. We aim to model age, and sex-specific reference values for the PROMIS Physical Function (PF), Upper Extremity (UE), and Pain Interference (PI) scales in populations age 50 and older in Germany, the UK, and the US.\nMethods: We collected PROMIS PF, UE, and PI data via telephone interviews from the general population in Germany (N = 921), the UK (N = 905), and the US (N = 900). We investigated differential item functioning (DIF) between countries using iterative hybrid ordinal logistic regression. To account for the measurement error of latent estimates and to obtain a continuous distribution of the latent variable, we imputed 25 data sets with plausible values. Each latent estimate was replaced by a random value drawn from the individual latent variable posterior distribution approximated by a normal distribution. We then utilized quantile regressions to model the 1st, 5th, 10th–90th, 95th, and 99th percentiles and their respective standard errors in each dataset based on different combinations of predictors (age, sex, country). According to Rubin’s rules, the estimated percentiles and corresponding standard errors were pooled across the imputed datasets to provide the respective reference values.\nResults: Three items from the PROMIS PF scale showed negligible DIF by country, indicating that all scales are valid for inter-country comparisons. Median regressions revealed significant effects of age (PF: b𝜏=.50= -0.33; PI: b𝜏=50= 0.08), sex (PF: b𝜏=50= -3.22; PI: b𝜏=50= 1.62) and country, indicating that stratification of reference data is warranted. The PF and UE scales showed considerable ceiling effects in all countries aged 50-69. For PI, this applied to all ages.\nConclusions: This paper illustrates a novel approach to model reference values for PROMIS measures based on individual patients’ characteristics. Substantial differences in the PROMIS scores between sex, age, and countries highlight the importance of such patient-specific reference values, enabling clinicians to utilize personalized reference values. Due to the use of plausible value imputation, the obtained population reference values can be compared to data collected with other PROMIS short forms or computer-adaptive tests.\nLink to Program"
  },
  {
    "objectID": "posts/talk-4.html",
    "href": "posts/talk-4.html",
    "title": "SIPS 2022",
    "section": "",
    "text": "Abstract\nThis session will tackle the multiverse approach to psychological science and data analysis: In each research project, researchers need to make a multitude of decisions, including decisions about which measurements to choose, how to pre-process data, or which analysis to run. Each of these decisions is potentially impactful and may create a unique universe out of a multiverse of possible outcomes. After a general introduction to the concept of a multiverse, we will host several guest speakers highlighting different facets and implementations of multiverse analysis. Two talks will hereby discuss fundamentals of multiverse analysis, focusing on visualization (Matthew Kay) and available software. Four talks will discuss various implementations of multiverse analysis: Jessica Dafflon will discuss multiverse analysis in developmental neuroscience, Constantin Yves Plessen will talk about multiverse meta-analyses and Justin Landy will talk about his project on crowdsourcing hypothesis tests (fourth speaker is tbd).\n\n\nLink to Program"
  },
  {
    "objectID": "posts/publicatation-1.html",
    "href": "posts/publicatation-1.html",
    "title": "Exploring the efficacy of psychological treatments for depression: a multiverse meta-analysis protocol",
    "section": "",
    "text": "Abstract\nIntroduction In the past four decades, over 700 randomised controlled trials (RCTs) and 80 meta-analyses have examined the efficacy of psychological treatments for depression. Overwhelming evidence suggests that all types of psychological treatments are effective. Yet, many aspects are still unexplored. Meta-analysts could perform hundreds of potential meta-analyses with the current literature, and a comprehensive bird’s-eye view of all published studies is missing. This protocol outlines how a multiverse meta-analysis can evaluate the entire body of the literature on psychological treatments of depression in a single analysis. Thereby, gaps of evidence and areas of robustness are highlighted.\nMethods and analysis We will conduct systematic literature searches in bibliographical databases (PubMed, Embase, PsycINFO and Cochrane Register of Controlled Trials) up until 1 January 2021. We will include all RCTs comparing a psychological treatment with a control condition. We will include studies published in English, German, Spanish or Dutch, and exclude trials on maintenance and relapse prevention as well as dissertations. Two independent researchers will check all records. All self-reported and clinician-rated instruments measuring depression are included. We will extract information on recruitment settings, target groups, age groups, comorbidity, intervention formats, psychotherapy types, number of sessions, control conditions and country. Two independent researchers will assess risk of bias using the Cochrane Risk of Bias assessment tool. As part of the multiverse meta-analysis, unweighted, fixed effect and random effects models will be calculated.\nEthics and dissemination As we will not collect any primary data, an ethical approval of this protocol is not required. We will publish the results in a peer-review journal and present them at international conferences. We will follow open science practices and provide our code and data.\n\n\nFull Text Link"
  },
  {
    "objectID": "posts/talk-6.html",
    "href": "posts/talk-6.html",
    "title": "Upcoming talk at DGPPN 2022",
    "section": "",
    "text": "Abstract\nBackground: Over the last decade, several meta-analyses and meta-reviews synthesized the evidence on the efficacy of digital mental health interventions for anxiety disorders—unfortunately with diverging conclusions. This leaves clinicians, researchers, and funding agencies with inconsistent recommendations. Methods: To provide a birds-eye-perspective of the entire field we conducted an umbrella review and a multiverse meta-analysis. We investigated whether the meta-analytical method or the inclusion criteria were responsible for these differences, or whether most potential meta-analyses would reach similar conclusions. Results: Our umbrella review included six meta-analyses with 84 primary studies. The included meta-analyses differed substantially in their AMSTAR-2 ratings, indicating heterogeneous quality. Our multiverse meta-analysis produced 1193 meta-analyses resulting from all possible analytical decisions. We identified several analytical decisions that consistently led to inflated effect size estimates. Larger effect sizes were found for the comparisons with wait-list control groups than for the comparisons with active control groups (mean Hedges g = 0.58 95% CI [0.40, 0.76] vs g = 0.26 95% CI [0.20, 0.42]). Larger effect sizes were found for digital interventions combining smartphone with internet interventions compared to standalone smartphone or internet applications. Meta-analyses that focused exclusively on guided interventions produced twice the effect sizes than meta-analyses on unguided interventions (g = 0.71, 95% CI [0.51, 0.90] vs g = 0.30, 95% CI [0.13, 0.47]). Conclusion: We identified several analytical decisions that consistently led to inflated effect size estimates. However, we also found that most decisions did not disproportionately influence the resulting summary effect size estimates, which suggests that meta-analytical findings on digital interventions for anxiety are robust.\n\n\nLink to Program"
  },
  {
    "objectID": "posts/talk-5.html",
    "href": "posts/talk-5.html",
    "title": "Upcoming talk at EACLIPT 2022",
    "section": "",
    "text": "Abstract\nBackground: At several stages in any meta-analysis, researchers must decide between multiple equally defensible choices (e.g., different study inclusion criteria, different ways of dealing with low-quality studies, different choices of methods, etc.). These different analytical decisions frequently result in various meta-analyses with overlapping research questions reaching different conclusions—resulting in ambiguous recommendations for clinicians, researchers, and funding agencies.\nMethods: In a multiverse meta-analysis, researchers identify all these possible stages for analytical decisions, determine alternative analysis steps at each stage, and implement them simultaneously. As a result, a multiverse meta-analysis reports the outcomes of all possible meta-analyses resulting from all of these possible combinations. Therefore, this method is a promising tool to help answer why some of these meta-analyses diverged, whether the meta-analytical method and exclusion criteria were decisive for these differences, or whether we would reach similar results with most analytical strategies.\nResults: We present the preliminary results of multiverse meta-analyses to evaluate the influence different analytical decisions might have had on two research questions, namely 1) the efficacy of psychological treatments for depression and 2) the efficacy of digital interventions for anxiety disorders.\nConclusion: We could identify several analytical decisions that consistently lead to inflated effect size estimates (e.g., the comparison with wait-list control groups, the inclusion of high risk of bias studies, and sometimes ignoring effect size dependency). However, we also identified many decisions that did not disproportionately influence the resulting summary effect size estimates, suggesting the overall robustness of meta-analytical findings on psychological treatments for depression and digital mental health research for anxiety.\n\n\nLink to Program"
  },
  {
    "objectID": "posts/talk-2.html",
    "href": "posts/talk-2.html",
    "title": "PHO 2021",
    "section": "",
    "text": "Objective: We investigate the validity of comparisons across general populations from Argentina, Germany, and the US by evaluating differential item functioning (DIF) for the PROMIS physical function (PROMIS-PF 2.0) ceiling items that were implemented to measure high physical ability. DIF is investigated as it could introduce biases to inter-country comparisons by potentially leading to systematically different physical function scores. If DIF is detected, individuals with the same ‘true’ underlying physical ability would score systematically different due specific cultural contexts or language differences.\nMethods: General population samples completed the 35 ceiling items of the PROMIS PF 2.0. DIF was assessed with hybrid logistic ordinal regression models and Nagelkerkes’ pseudo R2-change of &gt; 0.02 as the critical cutoff value indicating the presence of DIF. The impact of DIF on item scores and the T-scores was additionally examined by inspecting both the item characteristic curves (ICCs) and test characteristic curves (TCCs).\nResults: Overall, 3601 persons participated—1001 from Argentina (mean age of 35.6 years, ranging from 18 to 69 years; 51% were female), 1000 from Germany (mean age of 44.9 years, ranging from 18 to 69; 52% were female), and 1600 from the US (mean age of 44.3 years, ranging from 18 to 88; 58% were female). For the comparison between Germany and the USA, 2 out of 35 items were flagged for DIF. For the comparison between Argentina and the US, 4 items were flagged and for the comparison between German and Argentinian items, 5 out of 35 items were flagged. Most DIF items had R2 values just above the critical value of 0.02 and all showed uniform DIF. The ICCs and TCCs showed that the magnitude and impact of DIF on the item and T-scores were negligible.\nConclusions: Our study supports the universal applicability of PROMIS across general populations from Argentina, Germany, and the US. Comparisons across persons from the general population are valid, when applying the PROMIS-PF 2.0 ceiling items."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Constantin Yves Plessen",
    "section": "",
    "text": "About\nI am an advocate for rigorous science and robust methods, dedicated to advancing evidence-based approaches across diverse fields. My work bridges the gap between research synthesis and practical application, ensuring that scientific insights drive meaningful, real-world outcomes. With expertise in meta-analyses, psychometrics, and interdisciplinary collaboration, I strive to improve decision-making through innovative, reliable, and impactful methodologies."
  },
  {
    "objectID": "about_long.html",
    "href": "about_long.html",
    "title": "About Me",
    "section": "",
    "text": "I am a psychologist, researcher, and advocate for rigorous, open, and robust science. My career has been driven by the belief that evidence-based medicine and patient-centered care must be at the forefront of modern healthcare. My work focuses on bridging the gap between research synthesis and practical application to ensure scientific insights drive meaningful, real-world outcomes."
  },
  {
    "objectID": "about_long.html#researcher-at-charité-center-for-patient-centered-outcomes-research",
    "href": "about_long.html#researcher-at-charité-center-for-patient-centered-outcomes-research",
    "title": "About Me",
    "section": "Researcher at Charité Center for Patient-Centered Outcomes Research",
    "text": "Researcher at Charité Center for Patient-Centered Outcomes Research\nOur healthcare system often falls short of being both evidence-based and patient-centered, which drives my motivation to advocate for change. At the Charité Center for Patient-Centered Outcomes Research, my work centered on the development and refinement of patient-reported outcomes, tools that capture health-related quality of life to ensure treatments are aligned with patients’ needs and well-being. These tools are crucial for transforming medicine from an eminence-based practice, guided by expert opinion, to an evidence-based approach that truly prioritizes patients.\nThrough partnerships like the Oxford-Berlin Partnership, I contributed to advancing patient reported outcome methodologies, such as validating the psychometric assumptions of orthopedic measures and addressing limitations like ceiling and floor effects. My work explored how researcher decisions influence outcomes, fostering more transparent and robust practices in patient-centered research.\nProjects like the development of a Shiny web application, which provides tailored reference values for interpreting PROMIS® Physical Function and Pain Interference scores, highlight my commitment to practical, actionable tools for clinicians. This aligns with my broader mission to ensure healthcare systems are as inclusive, equitable, and effective as possible."
  },
  {
    "objectID": "about_long.html#phd-researcher-at-vu-amsterdam",
    "href": "about_long.html#phd-researcher-at-vu-amsterdam",
    "title": "About Me",
    "section": "PhD Researcher at VU Amsterdam",
    "text": "PhD Researcher at VU Amsterdam\nDuring my time at the VU Amsterdam, my research was driven by a fascination with the robustness of evidence in psychological interventions for mental health. Meta-analyses are often viewed as the gold standard in evidence-based practices, yet their outcomes can vary widely depending on analytical choices. To explore this, I conducted over 10,000 meta-analyses on psychotherapy and digital interventions for depression and anxiety, uncovering how researcher degrees of freedom can influence results. This work underscored the importance of transparent methodologies to mitigate biases and strengthen scientific reliability.\nCollaborating with the Metapsy Project, I contributed to transforming vast datasets into actionable insights for mental health research. The project’s innovative approach to meta-analytic research domains aimed to reduce research waste and promote transparency, values that remain central to my work."
  },
  {
    "objectID": "about_long.html#teaching-and-collaboration",
    "href": "about_long.html#teaching-and-collaboration",
    "title": "About Me",
    "section": "Teaching and Collaboration",
    "text": "Teaching and Collaboration\nIn addition to research, I have taught courses on evidence-based medicine, meta-analyses, and communication skills. These experiences have honed my ability to translate complex findings into actionable insights, whether for students, clinicians, or interdisciplinary teams.\nCollaborating on initiatives like WerteRadar and participating in the SPOKES Think Tank have deepened my engagement with the broader implications of science—such as fostering healthier academic cultures and empowering patients to make informed decisions about data sharing."
  },
  {
    "objectID": "about_long.html#motivation",
    "href": "about_long.html#motivation",
    "title": "About Me",
    "section": "Motivation",
    "text": "Motivation\nWhat motivates me is the pursuit of clarity and rigor in science. Whether addressing researcher degrees of freedom in psychometrics, ensuring cross-cultural fairness in PRO measures, or scrutinizing the robustness of meta-analyses, my goal is to challenge norms and elevate standards. This approach stems from a deep commitment to evidence-based practices that serve humanity and promote equity.\nThis About Me section might be a bit excessive, but I believe it is important to give appropriate contexts for research, to better understand the motivation behind research projects and scientific papers, and understand prior beliefs and conflicts of interest."
  }
]